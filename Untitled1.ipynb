{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import numpy as np\n",
    "folder = '/Users/chenjing/PycharmProjects/mytask/test/1.3.6.1.4.1.14519.5.2.1.6279.6001.109002525524522225658609808059_0310_0026_0057.npy'\n",
    "#f = open(folder,'rb')\n",
    "#print(len(f.read()))\n",
    "print(np.load(folder))\n",
    "#data = np.array([255],dtype=np.uint8)\n",
    "#np.save(name,data)\n",
    "#print(np.load(name).tostring())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "INFO:tensorflow:Starting standard services.\n",
      "INFO:tensorflow:Starting queue runners.\n",
      "(array([[[[ 5.],\n",
      "         [ 6.]],\n",
      "\n",
      "        [[ 7.],\n",
      "         [ 8.]]],\n",
      "\n",
      "\n",
      "       [[[ 5.],\n",
      "         [ 6.]],\n",
      "\n",
      "        [[ 7.],\n",
      "         [ 8.]]]], dtype=float32), array([0, 0], dtype=int32))\n",
      "INFO:tensorflow:Recording summary at step None.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "dtype = np.int8\n",
    "size = 1\n",
    "IMAGE_SIZE = 2\n",
    "NUM_CLASSES = 10\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n",
    "NUM_THREADS = 1\n",
    "\n",
    "name = 'test/test.bin'\n",
    "data = np.array([1,2,3,4,5,0,1,2,3,4,1,7,8,9,6,0,5,6,7,8], dtype=dtype).tostring()\n",
    "f = open(name, 'wb')\n",
    "f.write(data)\n",
    "f.close()\n",
    "\n",
    "def read(filename_queue):\n",
    "    class CIFAR10Record(object):\n",
    "        pass\n",
    "    result = CIFAR10Record()\n",
    "    label_bytes = 1  # 2 for CIFAR-100\n",
    "    result.height = IMAGE_SIZE\n",
    "    result.width = IMAGE_SIZE\n",
    "    result.depth = 1\n",
    "    image_bytes = result.height * result.width * result.depth\n",
    "    \n",
    "    # Every record consists of a label followed by the image, with a\n",
    "    # fixed number of bytes for each.\n",
    "    record_bytes = (label_bytes + image_bytes) * size\n",
    "    \n",
    "    # Read a record, getting filenames from the filename_queue\n",
    "    # header or footer in the CIFAR-10 format, so we leave header_bytes\n",
    "    # and footer_bytes at their default of 0.\n",
    "    reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n",
    "    result.key, value = reader.read(filename_queue)\n",
    "    \n",
    "    # Convert from a string to a vector of uint8 that is record_bytes long.\n",
    "    record_bytes = tf.decode_raw(value, dtype)\n",
    "    \n",
    "    # The first bytes represent the label, which we convert from uint8->int32.\n",
    "    result.label = tf.cast(\n",
    "    tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32)\n",
    "\n",
    "    # The remaining bytes after the label represent the image, which we reshape\n",
    "    # from [depth * height * width] to [depth, height, width].\n",
    "    depth_major = tf.reshape(\n",
    "    tf.strided_slice(record_bytes, [label_bytes],\n",
    "                       [label_bytes + image_bytes]),\n",
    "      [result.depth, result.height, result.width])\n",
    "    # Convert from [depth, height, width] to [height, width, depth].\n",
    "    result.uint8image = tf.transpose(depth_major, [1, 2, 0])\n",
    "\n",
    "    return result\n",
    "def _generate_image_and_label_batch(image, label, min_queue_examples,\n",
    "                                    batch_size, shuffle):\n",
    "    \"\"\"Construct a queued batch of images and labels.\n",
    "    Args:\n",
    "      image: 3-D Tensor of [height, width, 3] of type.float32.\n",
    "      label: 1-D Tensor of type.int32\n",
    "      min_queue_examples: int32, minimum number of samples to retain\n",
    "        in the queue that provides of batches of examples.\n",
    "      batch_size: Number of images per batch.\n",
    "      shuffle: boolean indicating whether to use a shuffling queue.\n",
    "    Returns:\n",
    "      images: Images. 4D tensor of [batch_size, height, width, 3] size.\n",
    "      labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "   # Create a queue that shuffles the examples, and then\n",
    "    # read 'batch_size' images + labels from the example queue.\n",
    "    num_preprocess_threads = NUM_THREADS\n",
    "    if shuffle:\n",
    "        images, label_batch = tf.train.shuffle_batch(\n",
    "            [image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size,\n",
    "            min_after_dequeue=min_queue_examples)\n",
    "    else:\n",
    "        images, label_batch = tf.train.batch(\n",
    "            [image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size)\n",
    "    # Display the training images in the visualizer.\n",
    "    tf.summary.image('images', images)\n",
    "\n",
    "    return images, tf.reshape(label_batch, [batch_size])\n",
    "\n",
    "def distorted_inputs(datadir,batch_size):\n",
    "    filenameQueue = tf.train.string_input_producer([name])\n",
    "    read_input = read(filenameQueue)\n",
    "    reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "    height = IMAGE_SIZE\n",
    "    width = IMAGE_SIZE\n",
    "    # Subtract off the mean and divide by the variance of the pixels.\n",
    "    #float_image = tf.image.per_image_standardization(reshaped_image)\n",
    "    float_image = reshaped_image\n",
    "    # Set the shapes of tensors.\n",
    "    float_image.set_shape([height, width, 1])\n",
    "    read_input.label.set_shape([1])\n",
    "\n",
    "    # Ensure that the random shuffling has good mixing properties.\n",
    "    min_fraction_of_examples_in_queue = 0.4\n",
    "    min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN *\n",
    "                           min_fraction_of_examples_in_queue)\n",
    "    print ('Filling queue with %d CIFAR images before starting to train. '\n",
    "         'This will take a few minutes.' % min_queue_examples)\n",
    "\n",
    "    # Generate a batch of images and labels by building up a queue of examples.\n",
    "    return _generate_image_and_label_batch(float_image, read_input.label,\n",
    "                                         min_queue_examples, batch_size,\n",
    "                                         shuffle=True)\n",
    "with tf.Graph().as_default():\n",
    "    filenameQueue = tf.train.string_input_producer([name])\n",
    "    data = distorted_inputs(filenameQueue,2)\n",
    "    sv = tf.train.Supervisor(logdir='save')\n",
    "    with sv.managed_session() as sess:\n",
    "        data = sess.run(data)\n",
    "        print(data)\n",
    "        #data2 = sess.run(data[1])\n",
    "        #print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "INFO:tensorflow:Starting standard services.\n",
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "dtype = np.int8\n",
    "size = 1\n",
    "IMAGE_SIZE = 40\n",
    "NUM_CLASSES = 10\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n",
    "NUM_THREADS = 1\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "\n",
    "def read(filename_queue):\n",
    "    class CIFAR10Record(object):\n",
    "        pass\n",
    "\n",
    "    result = CIFAR10Record()\n",
    "    label_bytes = 1  # 2 for CIFAR-100\n",
    "    result.height = IMAGE_SIZE\n",
    "    result.width = IMAGE_SIZE\n",
    "    result.depth = 1\n",
    "    image_bytes = result.height * result.width * result.depth\n",
    "\n",
    "    # Every record consists of a label followed by the image, with a\n",
    "    # fixed number of bytes for each.\n",
    "    record_bytes = (label_bytes + image_bytes) * size\n",
    "\n",
    "    # Read a record, getting filenames from the filename_queue\n",
    "    # header or footer in the CIFAR-10 format, so we leave header_bytes\n",
    "    # and footer_bytes at their default of 0.\n",
    "    reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n",
    "    result.key, value = reader.read(filename_queue)\n",
    "\n",
    "    # Convert from a string to a vector of uint8 that is record_bytes long.\n",
    "    record_bytes = tf.decode_raw(value, dtype)\n",
    "\n",
    "    # The first bytes represent the label, which we convert from uint8->int32.\n",
    "    result.label = tf.cast(\n",
    "        tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32)\n",
    "\n",
    "    # The remaining bytes after the label represent the image, which we reshape\n",
    "    # from [depth * height * width] to [depth, height, width].\n",
    "    depth_major = tf.reshape(\n",
    "        tf.strided_slice(record_bytes, [label_bytes],\n",
    "                         [label_bytes + image_bytes]),\n",
    "        [result.height * result.width])\n",
    "    result.uint8image = depth_major\n",
    "    # Convert from [depth, height, width] to [height, width, depth].\n",
    "    #result.uint8image = tf.transpose(depth_major, [1, 2, 0])\n",
    "    #tf.reshape(result.uint8image, shape=[-1])\n",
    "    #tf.contrib.layers.flatten(result.uint8image)\n",
    "    return result\n",
    "\n",
    "\n",
    "def _generate_image_and_label_batch(image, label, min_queue_examples,\n",
    "                                    batch_size, shuffle):\n",
    "    \"\"\"Construct a queued batch of images and labels.\n",
    "    Args:\n",
    "      image: 3-D Tensor of [height, width, 3] of type.float32.\n",
    "      label: 1-D Tensor of type.int32\n",
    "      min_queue_examples: int32, minimum number of samples to retain\n",
    "        in the queue that provides of batches of examples.\n",
    "      batch_size: Number of images per batch.\n",
    "      shuffle: boolean indicating whether to use a shuffling queue.\n",
    "    Returns:\n",
    "      images: Images. 4D tensor of [batch_size, height, width, 3] size.\n",
    "      labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    # Create a queue that shuffles the examples, and then\n",
    "    # read 'batch_size' images + labels from the example queue.\n",
    "    num_preprocess_threads = NUM_THREADS\n",
    "    if shuffle:\n",
    "        images, label_batch = tf.train.shuffle_batch(\n",
    "            [image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size,\n",
    "            min_after_dequeue=min_queue_examples)\n",
    "    else:\n",
    "        images, label_batch = tf.train.batch(\n",
    "            [image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + 3 * batch_size)\n",
    "    # Display the training images in the visualizer.\n",
    "    tf.summary.image('images', images)\n",
    "    return images, tf.reshape(label_batch, [batch_size])\n",
    "\n",
    "\n",
    "def distorted_inputs(datadir):\n",
    "    directory = glob.glob(datadir)\n",
    "    filenameQueue = tf.train.string_input_producer(directory)\n",
    "    read_input = read(filenameQueue)\n",
    "\n",
    "    reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "    reshaped_image = tf.reshape(reshaped_image,[1600])\n",
    "    height = IMAGE_SIZE\n",
    "    width = IMAGE_SIZE\n",
    "    # Subtract off the mean and divide by the variance of the pixels.\n",
    "    # float_image = tf.image.per_image_standardization(reshaped_image)\n",
    "    float_image = reshaped_image\n",
    "    # Set the shapes of tensors.\n",
    "    #float_image.set_shape([1])\n",
    "    read_input.label.set_shape([1])\n",
    "    # Ensure that the random shuffling has good mixing properties.\n",
    "    min_fraction_of_examples_in_queue = 0.4\n",
    "    min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN *\n",
    "                             min_fraction_of_examples_in_queue)\n",
    "    print ('Filling queue with %d CIFAR images before starting to train. '\n",
    "           'This will take a few minutes.' % min_queue_examples)\n",
    "\n",
    "    # Generate a batch of images and labels by building up a queue of examples.\n",
    "    return _generate_image_and_label_batch(float_image, read_input.label,\n",
    "                                           min_queue_examples, batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "datadir = \"/Users/chenjing/PycharmProjects/mytask/dest/*.bin\"\n",
    "with tf.Graph().as_default():\n",
    "    data = distorted_inputs(datadir)\n",
    "    sv = tf.train.Supervisor(logdir='save')\n",
    "    with sv.managed_session() as sess:\n",
    "        data = sess.run(data)\n",
    "        print(data.shape)\n",
    "        # data2 = sess.run(data[1])\n",
    "        # print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.array([[1,2,3],[4,5]])\n",
    "result = []\n",
    "for i in data:\n",
    "    result =result + i\n",
    "    #np.append(result,i)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
